{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 demo for CAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Run block for required dependencies:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch>=2.1.2 (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision>=0.16.2 (from -r requirements.txt (line 2))\n",
      "  Downloading torchvision-0.17.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.20.2 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Collecting opencv-python>=4.9.0.80 (from -r requirements.txt (line 4))\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=10.1.2 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (10.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.4 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (3.8.0)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2.2.1)\n",
      "Collecting PyYAML>=6.0.1 (from -r requirements.txt (line 8))\n",
      "  Downloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting scipy>=1.10.1 (from -r requirements.txt (line 9))\n",
      "  Downloading scipy-1.13.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m435.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.66.1 (from -r requirements.txt (line 10))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m651.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ultralytics>=8.1.2 (from -r requirements.txt (line 11))\n",
      "  Downloading ultralytics-8.1.42-py3-none-any.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.31.0 (from -r requirements.txt (line 12))\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting remote-kernel>=1.1 (from -r requirements.txt (line 13))\n",
      "  Downloading remote_kernel-1.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filelock (from torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from torch>=2.1.2->-r requirements.txt (line 1)) (4.10.0)\n",
      "Collecting sympy (from torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting fsspec (from torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from matplotlib>=3.7.4->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from pandas>=2.0.3->-r requirements.txt (line 7)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from pandas>=2.0.3->-r requirements.txt (line 7)) (2023.3)\n",
      "Requirement already satisfied: psutil in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ultralytics>=8.1.2->-r requirements.txt (line 11)) (5.9.0)\n",
      "Collecting py-cpuinfo (from ultralytics>=8.1.2->-r requirements.txt (line 11))\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting thop>=0.1.1 (from ultralytics>=8.1.2->-r requirements.txt (line 11))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics>=8.1.2->-r requirements.txt (line 11))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->-r requirements.txt (line 12))\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.31.0->-r requirements.txt (line 12))\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->-r requirements.txt (line 12))\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.31.0->-r requirements.txt (line 12))\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting paramiko (from remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading paramiko-3.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting sshtunnel (from remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading sshtunnel-0.4.0-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting jupyter (from remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Requirement already satisfied: six>=1.5 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.4->-r requirements.txt (line 6)) (1.16.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting notebook (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading notebook-7.1.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qtconsole (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading qtconsole-5.5.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading nbconvert-7.16.3-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (6.29.3)\n",
      "Collecting ipywidgets (from jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting bcrypt>=3.2 (from paramiko->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting cryptography>=3.3 (from paramiko->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Collecting pynacl>=1.5 (from paramiko->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl.metadata (8.7 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=2.1.2->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.3->paramiko->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading cffi-1.16.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: appnope in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (8.22.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (5.14.2)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from jupyter-console->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (3.0.42)\n",
      "Requirement already satisfied: pygments in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from jupyter-console->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (2.17.2)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading nbformat-5.10.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading tinycss2-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_server-2.13.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1 (from notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyterlab_server-2.25.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab<4.2,>=4.1.1 (from notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyterlab-4.1.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.3->paramiko->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: decorator in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (4.2.0)\n",
      "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting argon2-cffi (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyter-server-terminals (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading Send2Trash-1.8.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client (from jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jupyter_lsp-2.2.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading Babel-2.14.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading json5-0.9.24-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting fastjsonschema (from nbformat>=5.7->nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading fastjsonschema-2.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.8.3)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading rpds_py-0.18.0-cp312-cp312-macosx_10_12_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.7.0)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/connormaurer/miniconda3/envs/data-struc/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13)) (0.2.2)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading webcolors-1.13-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->remote-kernel>=1.1->-r requirements.txt (line 13))\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading torchvision-0.17.2-cp312-cp312-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp312-cp312-macosx_10_9_x86_64.whl (178 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-macosx_10_9_x86_64.whl (39.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics-8.1.42-py3-none-any.whl (749 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m749.1/749.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading remote_kernel-1.1-py3-none-any.whl (25 kB)\n",
      "Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp312-cp312-macosx_10_9_x86_64.whl (122 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.9/225.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading sshtunnel-0.4.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.5/528.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl (14 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-macosx_10_10_universal2.whl (349 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.9/349.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading nbconvert-7.16.3-py3-none-any.whl (257 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.4/257.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.16.0-cp312-cp312-macosx_10_9_x86_64.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_server-2.13.0-py3-none-any.whl (383 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab-4.1.5-py3-none-any.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_server-2.25.4-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading Babel-2.14.0-py3-none-any.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading json5-0.9.24-py3-none-any.whl (30 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_lsp-2.2.4-py3-none-any.whl (69 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastjsonschema-2.19.1-py3-none-any.whl (23 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.18.0-cp312-cp312-macosx_10_12_x86_64.whl (338 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.8/338.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading webcolors-1.13-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Installing collected packages: webencodings, py-cpuinfo, mpmath, fastjsonschema, widgetsnbextension, websocket-client, webcolors, urllib3, uri-template, types-python-dateutil, tqdm, tinycss2, terminado, sympy, soupsieve, sniffio, send2trash, scipy, rpds-py, rfc3986-validator, rfc3339-validator, qtpy, PyYAML, python-json-logger, pycparser, prometheus-client, pandocfilters, overrides, opencv-python, networkx, mistune, MarkupSafe, jupyterlab-widgets, jupyterlab-pygments, jsonpointer, json5, idna, h11, fsspec, fqdn, filelock, defusedxml, charset-normalizer, certifi, bleach, bcrypt, babel, attrs, async-lru, requests, referencing, jupyter-server-terminals, jinja2, httpcore, cffi, beautifulsoup4, arrow, anyio, torch, seaborn, pynacl, jsonschema-specifications, isoduration, httpx, cryptography, argon2-cffi-bindings, torchvision, thop, paramiko, jsonschema, ipywidgets, argon2-cffi, ultralytics, sshtunnel, qtconsole, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter, remote-kernel\n",
      "Successfully installed MarkupSafe-2.1.5 PyYAML-6.0.1 anyio-4.3.0 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.4 attrs-23.2.0 babel-2.14.0 bcrypt-4.1.2 beautifulsoup4-4.12.3 bleach-6.1.0 certifi-2024.2.2 cffi-1.16.0 charset-normalizer-3.3.2 cryptography-42.0.5 defusedxml-0.7.1 fastjsonschema-2.19.1 filelock-3.13.3 fqdn-1.5.1 fsspec-2024.3.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.6 ipywidgets-8.1.2 isoduration-20.11.0 jinja2-3.1.3 json5-0.9.24 jsonpointer-2.4 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.10.0 jupyter-lsp-2.2.4 jupyter-server-2.13.0 jupyter-server-terminals-0.5.3 jupyterlab-4.1.5 jupyterlab-pygments-0.3.0 jupyterlab-server-2.25.4 jupyterlab-widgets-3.0.10 mistune-3.0.2 mpmath-1.3.0 nbclient-0.10.0 nbconvert-7.16.3 nbformat-5.10.3 networkx-3.2.1 notebook-7.1.2 notebook-shim-0.2.4 opencv-python-4.9.0.80 overrides-7.7.0 pandocfilters-1.5.1 paramiko-3.4.0 prometheus-client-0.20.0 py-cpuinfo-9.0.0 pycparser-2.22 pynacl-1.5.0 python-json-logger-2.0.7 qtconsole-5.5.1 qtpy-2.4.1 referencing-0.34.0 remote-kernel-1.1 requests-2.31.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.18.0 scipy-1.13.0 seaborn-0.13.2 send2trash-1.8.2 sniffio-1.3.1 soupsieve-2.5 sshtunnel-0.4.0 sympy-1.12 terminado-0.18.1 thop-0.1.1.post2209072238 tinycss2-1.2.1 torch-2.2.2 torchvision-0.17.2 tqdm-4.66.2 types-python-dateutil-2.9.0.20240316 ultralytics-8.1.42 uri-template-1.3.0 urllib3-2.2.1 webcolors-1.13 webencodings-0.5.1 websocket-client-1.7.0 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# use this block to download requirements into virtual environment\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import statements:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Importing training dataset for demo</u>\n",
    "\n",
    "For this demo, we will be training a YOLOv8 on African wildlife imagery pulled from https://ultralytics.com/assets/african-wildlife.zip. From ultralytics, \"This dataset showcases four common animal classes typically found in South African nature reserves. It includes images of African wildlife such as buffalo, elephant, rhino, and zebra, providing valuable insights into their characteristics. Essential for training computer vision algorithms, this dataset aids in identifying animals in various habitats, from zoos to forests, and supports wildlife research.... \n",
    "\n",
    "The African wildlife objects detection dataset is split into three subsets:\n",
    "\n",
    "Training set: Contains 1052 images, each with corresponding annotations.\n",
    "Validation set: Includes 225 images, each with paired annotations.\n",
    "Testing set: Comprises 227 images, each with paired annotations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m url_of_yaml \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/african-wildlife.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# directory to be saved into\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m wd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      9\u001b[0m zip_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(wd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manimals.zip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m yaml_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(wd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# using requests, download zip file and extract contents\n",
    "\n",
    "# url of zipfile\n",
    "url_of_zip = 'https://ultralytics.com/assets/african-wildlife.zip'\n",
    "url_of_yaml = 'https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/african-wildlife.yaml'\n",
    "\n",
    "# directory to be saved into\n",
    "wd = os.getcwd()\n",
    "zip_directory = os.path.join(wd, 'animals.zip')\n",
    "yaml_directory = os.path.join(wd, 'data.yaml')\n",
    "\n",
    "# download request\n",
    "response = requests.get(url_of_zip)\n",
    "with open(zip_directory, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "response2 = requests.get(url_of_yaml)\n",
    "with open(yaml_directory, 'wb') as f:\n",
    "    f.write(response2.content)\n",
    "\n",
    "# use the working directory as the extraction target\n",
    "extract_to = wd  # Since we're extracting to the working directory\n",
    "\n",
    "# extract the zip file\n",
    "with zipfile.ZipFile(zip_directory, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clear directory of training files if needed:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file animals.zip has been deleted.\n",
      "The file data.yaml has been deleted.\n",
      "The directory ./train has been deleted.\n",
      "The directory ./test has been deleted.\n",
      "The directory ./valid has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# initialize file name\n",
    "file_name = 'animals.zip'\n",
    "file_name2 = 'data.yaml'\n",
    "\n",
    "# construct the file path\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "file_path2 = os.path.join(os.getcwd(), file_name2)\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"The file {file_name} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist.\")\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path2):\n",
    "    os.remove(file_path2)\n",
    "    print(f\"The file {file_name2} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name2} does not exist.\")\n",
    "\n",
    "# list of directory paths you want to delete\n",
    "directories = [\"./train\", \"./test\", \"./valid\"]\n",
    "\n",
    "# loop through each directory in the list\n",
    "for directory_path in directories:\n",
    "\n",
    "    # check if the directory exists\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        \n",
    "        # use shutil.rmtree() to delete the directory\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"The directory {directory_path} has been deleted.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"The directory {directory_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Training the detection model on local machine</u>\n",
    "\n",
    "This block will train the YOLO model using your local machine. Depending on the size of the training/val data and model size, this could be too computationally intensive for your hardware; we will discuss using UARK's high performance computing center if this is the case.\n",
    "\n",
    "<b>Hyperparameters</b>\n",
    "\n",
    "YOLOv8 has a handful of customizable hyperparameters you can read about here: https://docs.ultralytics.com/usage/cfg/#train-settings. Hyperparameters affect how YOLO is trained and can subsequently affect accuracy and time of convergence.\n",
    "\n",
    "This code block will prompt you for a few commonly customized hyperparameters.\n",
    "\n",
    "A note about batch size and optimizer: using batch size = -1 will find the computationally optimal batch size for your local machine. Similarly, using optimizer = auto will do the same.\n",
    "\n",
    "<b>Configuration</b>\n",
    "\n",
    "In your working directory, there should now be train, test, and valid folders. These are the image sets and associated annotations YOLO will be trained on. There should also be a data.yaml file; this yaml file tells the model the configuration of your directory, i.e. where to find the training data it needs.\n",
    "\n",
    "<b>Tensorboard Updates</b>\n",
    "\n",
    "TensorBoard offers an enhanced visualization experience for monitoring the YOLO (You Only Look Once) training process, providing deep insights into various metrics such as loss components, learning rate, and performance indicators like precision, recall, and mean Average Precision (mAP). Its integration with YOLO allows for real-time tracking of these metrics, enabling the identification and resolution of training challenges swiftly. The visualization of weight distributions, feature maps, and prediction outcomes further aids in understanding the model's learning behavior. \n",
    "\n",
    "TensorBoard will also provide a training time for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if cuda GPU training is available. if not, set to CPU training.\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(\"Using {}.\".format(device_name))\n",
    "\n",
    "# load a model\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.to(device_name)\n",
    "\n",
    "# prompt for hyperparameters\n",
    "print(\"\\033[1m\" + \"Hyperparameter intialization\" + \"\\033[0m\")\n",
    "\n",
    "# epochs\n",
    "print(f'Enter the number of epochs: ')\n",
    "epochs = int(input())\n",
    "print(epochs)\n",
    "\n",
    "# batch size\n",
    "print(f'Enter the batch size: ')\n",
    "batch_size = int(input())\n",
    "print(batch_size)\n",
    "\n",
    "# optimizer\n",
    "print(f'Enter the optimizer (SGD, Adam, AdamW, NAdam, RAdam, RMSProp, or auto): ')\n",
    "optimizer = input()\n",
    "print(optimizer)\n",
    "\n",
    "# cos_lr\n",
    "print('Enter status of cos_lr (False or True): ')\n",
    "cos_lr = bool(input())\n",
    "print(cos_lr)\n",
    "\n",
    "# train model\n",
    "results = model.train(data=\"data.yaml\", epochs=epochs, batch=batch_size, optimizer=optimizer, cos_lr=cos_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Training the detection model on UARK's high performance computing servers</u>\n",
    "\n",
    "Once again, training machine learning models on a laptop or PC is possible on a couple thousand of images, but the model tuning is demanding of most PC and laptop processers. Industrial scale GPUs, like NVIDIA's V100, are designed to execute a greater load of operations at the same time and are well equipped for math heavy machine learning algorithms. These GPUs allow for fitting models with a more complicated architecture to a larger dataset. \n",
    "\n",
    "The Arkansas HPC (High performance computer) server has 20 Industrial scale GPUs for computationally heavy programs. The AHPCC is available to faculty, staff and students at all of the Arkansas public universities. \n",
    "\n",
    "For our purposes, we will train the same model on a larger set of training data using these GPUs. Our process will walk through how to run these files on the AHPC server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the University of Arkansas HPC Server\n",
    "\n",
    "<u> Setup </u>\n",
    "\n",
    "You will need an account to use the GPUs on the AHPC server.\n",
    "U of A students can request an account to use the AHPC here: https://hpc.uark.edu/hpc-support/user-account-requests/internal.php\n",
    "\n",
    "You must be connected to university wifi or connected to the university VPN. Connections outside of the university network will fail on the server side.\n",
    "\n",
    "Test your connection by signing in to a login node. Enter a bash terminal and log in with this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <username> should be replaced by your uark username\n",
    "ssh <username>@hpc-portal2.hpc.uark.edu \n",
    "# This will prompt you to enter your UARK password to finish connecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now able to upload files to the server that may run on the AHPC GPU nodes. Now we need to format files to send to the server GPU. A computation node needs to know the code to run, the files that a code script accesses, and the packages necessary to run the script. \n",
    "\n",
    "1) Convert notebook code to python script\n",
    "2) Locate all build files and training data to one location\n",
    "3) Send the python environment needed to train the data as a container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Python Script\n",
    "\n",
    "Copy and paste the next to code chunk into a new python script. Call it \"train_model.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_model.py\n",
    "~~~~~~~~~~~~\n",
    "Used to train YOLO models on UARK hpc.\n",
    "\"\"\"\n",
    "\n",
    "# Setting environmental variable and import statements\n",
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from typing import List, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Specifying cuda GPU memory allocation. Required in google colab to deal with memory overrun, using as safeguard for HPC\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'\n",
    "\n",
    "# Intializing GPU use if available for training.\n",
    "if torch.cuda.is_available():\n",
    "    device_name = torch.device(\"cuda\")\n",
    "else:\n",
    "    device_name = torch.device('cpu')\n",
    "print(f\"Using {device_name} for training.\")\n",
    "\n",
    "# load a model\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.to(device_name)\n",
    "\n",
    "# prompt for hyperparameters\n",
    "print(\"\\033[1m\" + \"Hyperparameter intialization\" + \"\\033[0m\")\n",
    "\n",
    "# epochs\n",
    "print(f'Enter the number of epochs: ')\n",
    "epochs = int(input())\n",
    "print(epochs)\n",
    "\n",
    "# batch size\n",
    "print(f'Enter the batch size: ')\n",
    "batch_size = int(input())\n",
    "print(batch_size)\n",
    "\n",
    "# optimizer\n",
    "print(f'Enter the optimizer (SGD, Adam, AdamW, NAdam, RAdam, RMSProp, or auto): ')\n",
    "optimizer = input()\n",
    "print(optimizer)\n",
    "\n",
    "# cos_lr\n",
    "print('Enter status of cos_lr (False or True): ')\n",
    "cos_lr = bool(input())\n",
    "print(cos_lr)\n",
    "\n",
    "# train model\n",
    "results = model.train(data=\"data.yaml\", epochs=epochs, batch=batch_size, optimizer=optimizer, cos_lr=cos_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Locate all build files and training data to one folder\n",
    "\n",
    "Make a copy of this directory and remove the python notebook from the new directory. The script, yaml file, and training data should be the only files in this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp -r upload_folder <current_dir> ..   #bash command to copy the '<current_dir>' called 'upload_folder' to the parent folder\n",
    "cd ..\n",
    "cd upload_folder                        # Enter the upload folder\n",
    "rm *.ipynb\n",
    "ls -a                                   # print all files in the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a folder called \"images\" that contains two folders of images and labels: one for training and one for validation. Both training and validation folders should have two folders inside: one for all of the images and one for all labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Output of training </u>\n",
    "\n",
    "By the end of training, YOLO models provide several key outputs that give insights into the model's performance and its capability to detect objects in images.\n",
    "\n",
    "<b> Loss Function </b>\n",
    "\n",
    "The loss function is a critical output of the training process, as it quantifies how well the YOLO model is performing. YOLO's loss function is composed of several components:\n",
    "\n",
    "- **Localization Loss**: Measures how accurately the model predicts the location of bounding boxes for each detected object.\n",
    "- **Confidence Loss**: Represents the error in the confidence scores for the bounding boxes, including those boxes that do not contain objects (background).\n",
    "- **Classification Loss**: Calculates the error in predicting the class of the detected objects.\n",
    "\n",
    "Monitoring the loss function during training helps in understanding how well the model learns to detect objects and classify them. A decreasing loss over epochs indicates that the model is learning effectively.\n",
    "\n",
    "<b> Precision and Recall </b>\n",
    "\n",
    "After training, evaluating the model's performance involves looking at precision and recall metrics:\n",
    "\n",
    "- **Precision**: Indicates the accuracy of the predictions, i.e., the percentage of correct positive predictions out of all positive predictions made.\n",
    "- **Recall**: Measures the model's ability to detect all relevant instances, i.e., the percentage of correct positive predictions out of all actual positives.\n",
    "\n",
    "These metrics are crucial for understanding the trade-off between correctly detecting objects (recall) and minimizing false positives (precision).\n",
    "\n",
    "<b> mAP (Mean Average Precision) </b>\n",
    "\n",
    "mAP is a comprehensive metric used to evaluate the accuracy of object detectors like YOLO. It averages the precision-recall curve into a single value, providing an overall measure of the model's performance across all classes and IoU (Intersection over Union) thresholds. High mAP values indicate a robust model capable of accurately detecting and classifying objects across different scenarios.\n",
    "\n",
    "<b> Detection Speed </b>\n",
    "\n",
    "YOLO is designed for real-time object detection, and its detection speed (usually measured in FPS, frames per second) is a crucial output. This metric tells us how fast the model can process images to detect objects, which is vital for applications requiring real-time analysis, such as video surveillance and autonomous driving.\n",
    "\n",
    "<b> Visualization of Detections </b>\n",
    "\n",
    "Finally, visualizing the detections made by the YOLO model on test images or videos is an intuitive way to understand the model's performance. These visualizations typically include bounding boxes around detected objects, class labels, and confidence scores. They provide immediate visual feedback on how well the model can detect and classify objects in various conditions.\n",
    "\n",
    "<b> Trained Model Directory Structure </b>\n",
    "\n",
    "After successfully training a YOLO model, the next steps involve accessing the trained model for inference or further fine-tuning. The trained model weights are typically saved in a specific directory structure, often under a `weights` folder and within `runs` folders for different experiments. Understanding how to navigate these folders and use the saved weights is crucial for applying your YOLO model to real-world tasks.\n",
    "\n",
    "- **Weights Folder**: This folder contains the saved weights of your model after training. YOLO saves weights at regular intervals during training, as well as the final weights once training is complete. The saved weights include:\n",
    "  - `best.pt`: The weights of the model that achieved the best performance on the validation set during training.\n",
    "  - `last.pt`: The weights of the model at the last training epoch. These may not be the best-performing weights but are useful for resuming training.\n",
    "  \n",
    "- **Runs Folder**: The `runs` folder is organized by training experiments. Each experiment (or training run) has its own subfolder, typically named with the experiment's start date and time or a custom name you specify. Within each experiment's folder, you'll find:\n",
    "  - Subfolders for each training phase (e.g., `train`, `val`), containing logs and outputs specific to those phases.\n",
    "  - TensorBoard logs, if TensorBoard was used during training, allowing you to visually monitor the training process.\n",
    "  - Any additional outputs specified during training, such as plots of the loss function over time, precision-recall curves, and example predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Clear runs and trained model if needed:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file yolov8n.pt has been deleted.\n",
      "The directory ./runs has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# initialize file name\n",
    "file_name = 'yolov8n.pt'\n",
    "\n",
    "# construct the file path\n",
    "file_path = os.path.join(os.getcwd(), file_name)\n",
    "\n",
    "# delete the zip file\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"The file {file_name} has been deleted.\")\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exist.\")\n",
    "\n",
    "# list of directory paths you want to delete\n",
    "directory_path = \"./runs\"\n",
    "\n",
    "# check if the directory exists\n",
    "if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "    \n",
    "    # use shutil.rmtree() to delete the directory\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"The directory {directory_path} has been deleted.\")\n",
    "\n",
    "else:\n",
    "    print(f\"The directory {directory_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Using the model for inference</u>\n",
    "\n",
    "Once a model is trained, it can be used for infernecnce on "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
